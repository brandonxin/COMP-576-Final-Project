{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/comp-576_expr_3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "ENCODER_NAME = \"resnext50_32x4d\"\n",
    "ENCODER_DEPTH = 5\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "# ENCODER_WEIGHTS = None\n",
    "DECODER_CHANNELS = [256, 128, 64, 32, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER_NAME,  # Backbone\n",
    "    encoder_depth=ENCODER_DEPTH,\n",
    "    encoder_weights=ENCODER_WEIGHTS,  # Pre-trained on ImageNet\n",
    "    decoder_channels=DECODER_CHANNELS[:ENCODER_DEPTH],\n",
    "    in_channels=3,  # RGB images\n",
    "    classes=1,  # Binary segmentation\n",
    "    activation=None,  # Logits for BCEWithLogitsLoss\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "\n",
    "        # Convert mask to tensor (single channel)\n",
    "        mask = (\n",
    "            torch.tensor(np.array(mask), dtype=torch.float32) / 255.0\n",
    "        )  # Normalize to [0, 1]\n",
    "        mask = mask.unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "path = kagglehub.dataset_download(\"mateuszbuda/lgg-mri-segmentation\")\n",
    "data_dir = os.path.join(path, \"kaggle_3m\")\n",
    "patients = os.listdir(data_dir)\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "for patient in patients:\n",
    "    patient_dir = os.path.join(data_dir, patient)\n",
    "    if os.path.isdir(patient_dir):\n",
    "        images = sorted(glob.glob(os.path.join(patient_dir, \"*[!mask].tif\")))\n",
    "        masks = [f\"{image.rsplit(\".\", 1)[0]}_mask.tif\" for image in images]\n",
    "        image_paths.extend(images)\n",
    "        mask_paths.extend(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation Split\n",
    "split_idx = int(0.8 * len(image_paths))\n",
    "train_images, val_images = image_paths[:split_idx], image_paths[split_idx:]\n",
    "train_masks, val_masks = mask_paths[:split_idx], mask_paths[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and Dataloaders\n",
    "train_dataset = BrainMRIDataset(train_images, train_masks, transform=transform)\n",
    "val_dataset = BrainMRIDataset(val_images, val_masks, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "class Dice(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(Dice, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = F.sigmoid(inputs)\n",
    "\n",
    "        # flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.0 * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return dice\n",
    "\n",
    "\n",
    "class DiceBCELoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = F.sigmoid(inputs)\n",
    "\n",
    "        # flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.0 * intersection + smooth) / (\n",
    "            inputs.sum() + targets.sum() + smooth\n",
    "        )\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction=\"mean\")\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# criterion = DiceLoss()\n",
    "dice = Dice()\n",
    "# criterion = DiceLoss()\n",
    "criterion = DiceBCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train DICE: 0.5421, Train Loss: 0.5210, Val DICE: 0.3841, Val Loss: 0.6278\n",
      "Duration: 159.87156796455383s\n",
      "Epoch 2/20, Train DICE: 0.8088, Train Loss: 0.2061, Val DICE: 0.4049, Val Loss: 0.6105\n",
      "Duration: 169.11816596984863s\n",
      "Epoch 3/20, Train DICE: 0.8405, Train Loss: 0.1724, Val DICE: 0.4345, Val Loss: 0.5787\n",
      "Duration: 169.9835970401764s\n",
      "Epoch 4/20, Train DICE: 0.8480, Train Loss: 0.1644, Val DICE: 0.4474, Val Loss: 0.5906\n",
      "Duration: 170.3609549999237s\n",
      "Epoch 5/20, Train DICE: 0.8530, Train Loss: 0.1586, Val DICE: 0.4409, Val Loss: 0.6003\n",
      "Duration: 169.8536229133606s\n",
      "Epoch 6/20, Train DICE: 0.8575, Train Loss: 0.1533, Val DICE: 0.5618, Val Loss: 0.4510\n",
      "Duration: 169.5381441116333s\n",
      "Epoch 7/20, Train DICE: 0.8812, Train Loss: 0.1285, Val DICE: 0.6525, Val Loss: 0.3679\n",
      "Duration: 169.78781485557556s\n",
      "Epoch 8/20, Train DICE: 0.8694, Train Loss: 0.1410, Val DICE: 0.7106, Val Loss: 0.3072\n",
      "Duration: 169.60931277275085s\n",
      "Epoch 9/20, Train DICE: 0.8794, Train Loss: 0.1311, Val DICE: 0.7507, Val Loss: 0.2711\n",
      "Duration: 169.836364030838s\n",
      "Epoch 10/20, Train DICE: 0.8806, Train Loss: 0.1304, Val DICE: 0.7816, Val Loss: 0.2444\n",
      "Duration: 169.84159994125366s\n",
      "Epoch 11/20, Train DICE: 0.8847, Train Loss: 0.1247, Val DICE: 0.8118, Val Loss: 0.2024\n",
      "Duration: 169.58830499649048s\n",
      "Epoch 12/20, Train DICE: 0.9012, Train Loss: 0.1077, Val DICE: 0.8066, Val Loss: 0.2071\n",
      "Duration: 169.72334909439087s\n",
      "Epoch 13/20, Train DICE: 0.8944, Train Loss: 0.1149, Val DICE: 0.8051, Val Loss: 0.2080\n",
      "Duration: 169.1352880001068s\n",
      "Epoch 14/20, Train DICE: 0.8972, Train Loss: 0.1124, Val DICE: 0.8185, Val Loss: 0.1977\n",
      "Duration: 169.53841185569763s\n",
      "Epoch 15/20, Train DICE: 0.8949, Train Loss: 0.1138, Val DICE: 0.8116, Val Loss: 0.2026\n",
      "Duration: 169.4742078781128s\n",
      "Epoch 16/20, Train DICE: 0.9081, Train Loss: 0.0998, Val DICE: 0.8149, Val Loss: 0.1976\n",
      "Duration: 169.96029615402222s\n",
      "Epoch 17/20, Train DICE: 0.8938, Train Loss: 0.1148, Val DICE: 0.8213, Val Loss: 0.1925\n",
      "Duration: 170.35038471221924s\n",
      "Epoch 18/20, Train DICE: 0.9017, Train Loss: 0.1063, Val DICE: 0.8168, Val Loss: 0.1962\n",
      "Duration: 170.6855821609497s\n",
      "Epoch 19/20, Train DICE: 0.9210, Train Loss: 0.0865, Val DICE: 0.8197, Val Loss: 0.1988\n",
      "Duration: 170.20410704612732s\n",
      "Epoch 20/20, Train DICE: 0.9152, Train Loss: 0.0924, Val DICE: 0.7763, Val Loss: 0.2531\n",
      "Duration: 170.05745601654053s\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "writer = SummaryWriter()\n",
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(EPOCHS):\n",
    "    tic = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_dice = 0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        train_loss += loss.item()\n",
    "        train_dice += dice(outputs, masks).item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_dice /= len(train_loader)\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_dice = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            val_dice += dice(outputs, masks).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_dice /= len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{EPOCHS}, \"\n",
    "        f\"Train DICE: {train_dice:.4f}, \"\n",
    "        f\"Train Loss: {train_loss:.4f}, \"\n",
    "        f\"Val DICE: {val_dice:.4f}, \"\n",
    "        f\"Val Loss: {val_loss:.4f}\"\n",
    "    )\n",
    "    toc = time.time()\n",
    "    print(f\"Duration: {toc - tic}s\")\n",
    "    writer.add_scalar(\"train/dice\", train_dice, epoch)\n",
    "    writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"validation/dice\", val_dice, epoch)\n",
    "    writer.add_scalar(\"validation/loss\", val_loss, epoch)\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_unetpp_model.pth\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_unetpp_model.pth\", weights_only=True))\n",
    "model.eval()\n",
    "for img_path, mask_path in zip(val_images, val_masks):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "    image = transform(image).to(DEVICE).unsqueeze(0)\n",
    "    output = model(image)\n",
    "\n",
    "    dir_name = img_path.rsplit(\"/\", 1)[1].rsplit(\".\", 1)[0]\n",
    "    dir_name = f\"validation/{dir_name}\"\n",
    "    if not os.path.exists(\"validation\"):\n",
    "        os.mkdir(\"validation\")\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    shutil.copy2(img_path, dir_name)\n",
    "    shutil.copy2(mask_path, dir_name)\n",
    "\n",
    "    # Save the mask as an image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    output_path = os.path.join(dir_name, \"output.tif\")\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp-576_expr_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
